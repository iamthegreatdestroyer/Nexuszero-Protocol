use std::fs;
use std::path::{Path, PathBuf};
use serde::Deserialize;

// Structure matching Criterion's estimates.json subset we need
#[derive(Deserialize)]
struct Estimates {
    mean: StatPoint,
    std_dev: StatPoint,
}

#[derive(Deserialize)]
struct StatPoint {
    point_estimate: f64,
}

#[derive(Debug)]
struct BenchRecord {
    group: String,
    name: String,
    mean_ns: f64,
    ops_sec: f64,
    variance_pct: f64,
}

fn main() -> anyhow::Result<()> {
    let criterion_root = PathBuf::from("target/criterion");
    if !criterion_root.exists() {
        eprintln!("No criterion output found at {:?}", criterion_root);
        return Ok(());
    }

    let mut records = Vec::new();
    walk_groups(&criterion_root, &mut records)?;

    // Group records by group for markdown output
    println!("# Auto-Parsed Benchmark Results\n");
    println!("Generated by parse_benchmarks.rs\n");

    use std::collections::BTreeMap;
    let mut by_group: BTreeMap<String, Vec<&BenchRecord>> = BTreeMap::new();
    for r in &records { by_group.entry(r.group.clone()).or_default().push(r); }

    for (group, list) in by_group {
        println!("## {}\n", group);
        println!("| Benchmark | Mean (ns) | Ops/sec | Var % |");
        println!("|-----------|-----------|---------|-------|");
        for r in list {
            println!(
                "| {} | {:>10.0} | {:>9.2} | {:>6.2} |",
                r.name, r.mean_ns, r.ops_sec, r.variance_pct
            );
        }
        println!();
    }

    Ok(())
}

fn walk_groups(root: &Path, out: &mut Vec<BenchRecord>) -> anyhow::Result<()> {
    for entry in fs::read_dir(root)? {
        let entry = entry?;
        let path = entry.path();
        if path.is_dir() {
            // Each top-level directory is a benchmark group (e.g., "lwe operations")
            collect_group(&path, out)?;
        }
    }
    Ok(())
}

fn collect_group(group_path: &Path, out: &mut Vec<BenchRecord>) -> anyhow::Result<()> {
    let group_name = group_path.file_name().unwrap().to_string_lossy().to_string();

    // Two patterns:
    // 1. subgroup/benchmark_variant/new/estimates.json (e.g., keygen/128-bit/new/estimates.json)
    // 2. benchmark_name/size/new/estimates.json for polynomial operations.
    for entry in fs::read_dir(group_path)? {
        let entry = entry?;
        let path = entry.path();
        if path.is_dir() {
            scan_nested(group_name.clone(), &path, out)?;
        }
    }
    Ok(())
}

fn scan_nested(group_name: String, dir: &Path, out: &mut Vec<BenchRecord>) -> anyhow::Result<()> {
    // Recursively search for estimates.json
    for entry in fs::read_dir(dir)? {
        let entry = entry?;
        let path = entry.path();
        if path.is_dir() {
            scan_nested(group_name.clone(), &path, out)?;
        } else if let Some(fname) = path.file_name() {
            if fname == "estimates.json" {
                if let Some(record) = parse_estimates(&group_name, &path) {
                    out.push(record);
                }
            }
        }
    }
    Ok(())
}

fn parse_estimates(group: &str, file: &Path) -> Option<BenchRecord> {
    let data = fs::read_to_string(file).ok()?;
    let est: Estimates = serde_json::from_str(&data).ok()?;
    // Derive benchmark name from path components (parent folders before 'new')
    let name = file.parent()?.parent()?.file_name()?.to_string_lossy().to_string();
    let mean = est.mean.point_estimate; // nanoseconds
    let std = est.std_dev.point_estimate;
    let ops_sec = 1e9_f64 / mean;
    let variance_pct = (std / mean) * 100.0;
    Some(BenchRecord { group: group.to_string(), name, mean_ns: mean, ops_sec, variance_pct })
}

// Unit tests for binary helper functions to increase coverage in CI
#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use std::time::{SystemTime, UNIX_EPOCH};

    #[test]
    fn test_parse_estimates_from_temp_file() {
        let mut tmp = std::env::temp_dir();
        tmp.push(format!("parse_benchmarks_test_{}", SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos()));
        std::fs::create_dir_all(&tmp).unwrap();
        let dir = tmp;
        let group = "sample-group";
        let nested = dir.join("subgroup/new");
        std::fs::create_dir_all(&nested).unwrap();
        let estimates_path = nested.join("estimates.json");
        let json = r#"{ "mean": { "point_estimate": 2000.0 }, "std_dev": { "point_estimate": 100.0 } }"#;
        fs::write(&estimates_path, json).unwrap();

        let rec = parse_estimates(group, &estimates_path).unwrap();
        assert_eq!(rec.group, group);
        assert_eq!(rec.name, "subgroup");
        assert_eq!(rec.mean_ns, 2000.0);
        assert!(rec.ops_sec > 0.0);
        assert!(rec.variance_pct > 0.0);
    }

    #[test]
    fn test_walk_groups_collects_records() {
        let mut tmp = std::env::temp_dir();
        tmp.push(format!("parse_benchmarks_test_{}", SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos()));
        let root = tmp.join("criterion");
        std::fs::create_dir_all(&root).unwrap();
        let subgroup = root.join("bench-a/sub1/new");
        std::fs::create_dir_all(&subgroup).unwrap();
        let estimates_path = subgroup.join("estimates.json");
        let json = r#"{ "mean": { "point_estimate": 1500.0 }, "std_dev": { "point_estimate": 50.0 } }"#;
        fs::write(&estimates_path, json).unwrap();

        let mut out = Vec::new();
        walk_groups(&root, &mut out).unwrap();
        assert!(out.len() >= 1);
        let rec = &out[0];
        assert_eq!(rec.group, "bench-a");
        assert_eq!(rec.name, "sub1");
    }
}